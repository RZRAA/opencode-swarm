# OpenCode Swarm v6.4 — Execution & Planning Tools

**Version**: 6.4.0 (Minor)
**Scope**: `test_runner`, `symbols`, `checkpoint` tools
**Breaking Changes**: test_engineer workflow updated to use `test_runner` tool; new `checkpoint` config block
**Dependencies**: v6.3 (`imports` tool used by `test_runner` graph mode)

---

## Overview

v6.3 completed the pre-reviewer pipeline. This release targets the execution and planning phases: `test_runner` normalizes test execution across all ecosystems, `symbols` gives the architect instant visibility into a module's public API, and `checkpoint` provides safe rollback points for multi-file changes.

---

## 1. `test_runner` — Unified Test Execution

### Purpose

Auto-detects the project's test framework, executes tests with the correct flags, and returns normalized JSON output. Eliminates the test_engineer's most common failure mode: constructing the wrong CLI invocation or failing to parse unstructured terminal output.

### Scope Modes

The tool supports three execution scopes:

- **`all`**: Run the full test suite. Equivalent to `bun test`, `pytest`, `cargo test`, etc.
- **`convention`**: Run only test files that correspond to specified source files by naming convention (e.g., `src/auth/login.ts` → `src/auth/login.test.ts` or `tests/auth/login.test.ts`). Zero dependency on the `imports` tool. Ships functional without v6.3.
- **`graph`**: Run test files that exercise specified source files by tracing the import graph. Uses the `imports` tool from v6.3 to find test files that directly or transitively import the target. Most accurate, but requires `imports` to be available.

### Implementation

#### `src/tools/test-runner.ts` (new file)

```typescript
import { execSync } from 'node:child_process';
import * as fs from 'node:fs';
import * as path from 'node:path';
import { type ToolDefinition, tool } from '@opencode-ai/plugin/tool';

interface TestResult {
  framework: string;
  scope: string;
  command: string;
  total: number;
  passed: number;
  failed: number;
  skipped: number;
  coveragePercent: number | null;
  duration_ms: number;
  success: boolean;
  failures: Array<{
    name: string;
    file: string;
    message: string;
  }>;
  rawOutput?: string;
}

interface FrameworkConfig {
  name: string;
  runCmd: string;
  coverageCmd: string;
  filePatterns: string[];
  parseOutput: (output: string) => Partial<TestResult>;
}

/**
 * Detect test framework from project configuration files.
 */
function detectFramework(cwd: string): FrameworkConfig | null {
  const pkgPath = path.join(cwd, 'package.json');

  // Check package.json for JS/TS projects
  if (fs.existsSync(pkgPath)) {
    const pkg = JSON.parse(fs.readFileSync(pkgPath, 'utf-8'));
    const deps = {
      ...pkg.dependencies,
      ...pkg.devDependencies,
    };

    // Bun test (check bun.lockb or bunfig.toml)
    if (fs.existsSync(path.join(cwd, 'bun.lockb')) ||
        fs.existsSync(path.join(cwd, 'bunfig.toml'))) {
      return {
        name: 'bun',
        runCmd: 'bun test',
        coverageCmd: 'bun test --coverage',
        filePatterns: ['**/*.test.ts', '**/*.test.tsx', '**/*.test.js', '**/*.spec.ts', '**/*.spec.js'],
        parseOutput: parseBunTestOutput,
      };
    }

    // Vitest
    if (deps.vitest) {
      return {
        name: 'vitest',
        runCmd: 'npx vitest run --reporter=json',
        coverageCmd: 'npx vitest run --coverage --reporter=json',
        filePatterns: ['**/*.test.ts', '**/*.test.tsx', '**/*.spec.ts', '**/*.spec.tsx'],
        parseOutput: parseVitestOutput,
      };
    }

    // Jest
    if (deps.jest || deps['@jest/core'] || pkg.jest) {
      return {
        name: 'jest',
        runCmd: 'npx jest --json',
        coverageCmd: 'npx jest --json --coverage',
        filePatterns: ['**/*.test.ts', '**/*.test.tsx', '**/*.test.js', '**/*.spec.ts', '**/*.spec.js'],
        parseOutput: parseJestOutput,
      };
    }

    // Mocha
    if (deps.mocha) {
      return {
        name: 'mocha',
        runCmd: 'npx mocha --reporter=json',
        coverageCmd: 'npx c8 mocha --reporter=json',
        filePatterns: ['**/*.test.ts', '**/*.test.js', '**/*.spec.ts', '**/*.spec.js'],
        parseOutput: parseMochaOutput,
      };
    }
  }

  // Python: pytest
  if (fs.existsSync(path.join(cwd, 'pyproject.toml')) ||
      fs.existsSync(path.join(cwd, 'setup.py')) ||
      fs.existsSync(path.join(cwd, 'pytest.ini')) ||
      fs.existsSync(path.join(cwd, 'setup.cfg'))) {
    return {
      name: 'pytest',
      runCmd: 'python -m pytest --tb=short -q',
      coverageCmd: 'python -m pytest --cov --cov-report=json --tb=short -q',
      filePatterns: ['**/test_*.py', '**/*_test.py', 'tests/**/*.py'],
      parseOutput: parsePytestOutput,
    };
  }

  // Rust: cargo test
  if (fs.existsSync(path.join(cwd, 'Cargo.toml'))) {
    return {
      name: 'cargo',
      runCmd: 'cargo test 2>&1',
      coverageCmd: 'cargo test 2>&1',
      filePatterns: ['**/tests/**/*.rs', 'src/**/*.rs'],
      parseOutput: parseCargoTestOutput,
    };
  }

  // PowerShell: Pester
  const hasPester = execSync(
    'find . -name "*.Tests.ps1" -maxdepth 4 2>/dev/null | head -1',
    { cwd, encoding: 'utf-8', timeout: 5000 }
  ).trim();
  if (hasPester) {
    return {
      name: 'pester',
      runCmd: 'pwsh -Command "Invoke-Pester -PassThru | ConvertTo-Json -Depth 5"',
      coverageCmd: 'pwsh -Command "Invoke-Pester -CodeCoverage (Get-ChildItem -Recurse -Filter *.ps1 | Where-Object { $_.Name -notmatch \'.Tests\\.\' }) -PassThru | ConvertTo-Json -Depth 5"',
      filePatterns: ['**/*.Tests.ps1'],
      parseOutput: parsePesterOutput,
    };
  }

  return null;
}

/**
 * Find test files for specific source files using naming convention.
 * Maps src/auth/login.ts → src/auth/login.test.ts, tests/auth/login.test.ts, etc.
 */
function findTestsByConvention(sourceFiles: string[], framework: FrameworkConfig, cwd: string): string[] {
  const testFiles: string[] = [];

  for (const src of sourceFiles) {
    const parsed = path.parse(src);
    const baseName = parsed.name;
    const dir = parsed.dir;

    // Common test file naming conventions
    const candidates = [
      // Same directory: login.test.ts, login.spec.ts
      path.join(dir, `${baseName}.test${parsed.ext}`),
      path.join(dir, `${baseName}.spec${parsed.ext}`),
      path.join(dir, `${baseName}.test.tsx`),
      path.join(dir, `${baseName}.spec.tsx`),
      // __tests__ directory
      path.join(dir, '__tests__', `${baseName}.test${parsed.ext}`),
      path.join(dir, '__tests__', `${baseName}.spec${parsed.ext}`),
      // Parallel tests/ directory (mirror structure)
      path.join('tests', dir.replace(/^src\/?/, ''), `${baseName}.test${parsed.ext}`),
      path.join('tests', dir.replace(/^src\/?/, ''), `${baseName}.spec${parsed.ext}`),
      // Python conventions
      path.join(dir, `test_${baseName}.py`),
      path.join(dir, `${baseName}_test.py`),
      path.join('tests', dir.replace(/^src\/?/, ''), `test_${baseName}.py`),
      // Pester conventions
      path.join(dir, `${baseName}.Tests.ps1`),
      path.join('tests', `${baseName}.Tests.ps1`),
    ];

    for (const candidate of candidates) {
      if (fs.existsSync(path.join(cwd, candidate))) {
        testFiles.push(candidate);
      }
    }
  }

  return [...new Set(testFiles)];
}

/**
 * Find test files using import graph analysis.
 * Requires the `imports` tool to be available.
 */
function findTestsByGraph(sourceFiles: string[], framework: FrameworkConfig, cwd: string): string[] {
  const testFiles: string[] = [];
  const testPatterns = framework.filePatterns.map(p =>
    new RegExp(p.replace(/\*\*/g, '.*').replace(/\*/g, '[^/]*'))
  );

  for (const src of sourceFiles) {
    try {
      // Use grep to find all files importing from this source
      const baseName = src.replace(/\.(ts|tsx|js|jsx|py|rs|ps1)$/, '');
      const name = path.basename(baseName);
      const extensions = '*.ts,*.tsx,*.js,*.jsx,*.py,*.rs,*.ps1';
      const includeFlags = extensions.split(',').map(e => `--include="${e}"`).join(' ');

      const matches = execSync(
        `grep -rl ${includeFlags} -E "(from|import|require).*${name}" . 2>/dev/null || true`,
        { cwd, encoding: 'utf-8', timeout: 15000, maxBuffer: 2 * 1024 * 1024 }
      ).trim();

      for (const file of matches.split('\n').filter(Boolean)) {
        const clean = file.replace(/^\.\//, '');
        // Check if this consumer is a test file
        if (testPatterns.some(p => p.test(clean))) {
          testFiles.push(clean);
        }
      }
    } catch {
      // Fall back to convention for this file
      testFiles.push(...findTestsByConvention([src], framework, cwd));
    }
  }

  return [...new Set(testFiles)];
}

// --- Output parsers ---

function parseBunTestOutput(output: string): Partial<TestResult> {
  const passMatch = output.match(/(\d+)\s+pass/);
  const failMatch = output.match(/(\d+)\s+fail/);
  const skipMatch = output.match(/(\d+)\s+skip/);
  const coverageMatch = output.match(/All files\s*\|\s*([\d.]+)/);

  const passed = passMatch ? parseInt(passMatch[1]) : 0;
  const failed = failMatch ? parseInt(failMatch[1]) : 0;
  const skipped = skipMatch ? parseInt(skipMatch[1]) : 0;

  const failures: TestResult['failures'] = [];
  const failPattern = /✗\s+(.+?)(?:\n\s+(.+))?/g;
  let match;
  while ((match = failPattern.exec(output)) !== null) {
    failures.push({ name: match[1].trim(), file: '', message: match[2]?.trim() || '' });
  }

  return {
    total: passed + failed + skipped,
    passed,
    failed,
    skipped,
    coveragePercent: coverageMatch ? parseFloat(coverageMatch[1]) : null,
    success: failed === 0,
    failures,
  };
}

function parseVitestOutput(output: string): Partial<TestResult> {
  try {
    const json = JSON.parse(output);
    const results = json.testResults || [];
    let passed = 0, failed = 0, skipped = 0;
    const failures: TestResult['failures'] = [];

    for (const suite of results) {
      for (const test of suite.assertionResults || []) {
        if (test.status === 'passed') passed++;
        else if (test.status === 'failed') {
          failed++;
          failures.push({
            name: test.fullName || test.title,
            file: suite.name || '',
            message: (test.failureMessages || []).join('\n').substring(0, 500),
          });
        } else skipped++;
      }
    }

    return { total: passed + failed + skipped, passed, failed, skipped, success: failed === 0, failures };
  } catch {
    return parseBunTestOutput(output); // Fallback to text parsing
  }
}

function parseJestOutput(output: string): Partial<TestResult> {
  try {
    // Jest --json output may have non-JSON preamble
    const jsonStart = output.indexOf('{');
    if (jsonStart === -1) return parseBunTestOutput(output);
    const json = JSON.parse(output.substring(jsonStart));

    const failures: TestResult['failures'] = [];
    for (const suite of json.testResults || []) {
      for (const test of suite.testResults || []) {
        if (test.status === 'failed') {
          failures.push({
            name: test.fullName || test.title,
            file: suite.name || '',
            message: (test.failureMessages || []).join('\n').substring(0, 500),
          });
        }
      }
    }

    return {
      total: json.numTotalTests || 0,
      passed: json.numPassedTests || 0,
      failed: json.numFailedTests || 0,
      skipped: json.numPendingTests || 0,
      success: json.success,
      failures,
      coveragePercent: json.coverageMap
        ? Object.values(json.coverageMap as Record<string, { s: Record<string, number> }>)
            .reduce((acc, file) => {
              const stmts = Object.values(file.s);
              const covered = stmts.filter(v => v > 0).length;
              return acc + (stmts.length > 0 ? covered / stmts.length : 0);
            }, 0) / Math.max(Object.keys(json.coverageMap).length, 1) * 100
        : null,
    };
  } catch {
    return parseBunTestOutput(output);
  }
}

function parseMochaOutput(output: string): Partial<TestResult> {
  try {
    const json = JSON.parse(output);
    const failures: TestResult['failures'] = (json.failures || []).map((f: { fullTitle: string; err: { message: string } }) => ({
      name: f.fullTitle, file: '', message: f.err?.message || '',
    }));
    return {
      total: (json.stats?.tests || 0),
      passed: (json.stats?.passes || 0),
      failed: (json.stats?.failures || 0),
      skipped: (json.stats?.pending || 0),
      success: (json.stats?.failures || 0) === 0,
      failures,
    };
  } catch {
    return parseBunTestOutput(output);
  }
}

function parsePytestOutput(output: string): Partial<TestResult> {
  const summaryMatch = output.match(/(\d+)\s+passed(?:,\s+(\d+)\s+failed)?(?:,\s+(\d+)\s+skipped)?/);
  const failures: TestResult['failures'] = [];
  const failPattern = /FAILED\s+(\S+)\s+-\s+(.+)/g;
  let m;
  while ((m = failPattern.exec(output)) !== null) {
    failures.push({ name: m[1], file: '', message: m[2] });
  }

  // Coverage from pytest-cov JSON output
  let coveragePercent: number | null = null;
  try {
    const covPath = path.join(process.cwd(), 'coverage.json');
    if (fs.existsSync(covPath)) {
      const cov = JSON.parse(fs.readFileSync(covPath, 'utf-8'));
      coveragePercent = cov.totals?.percent_covered || null;
    }
  } catch { /* ignore */ }

  return {
    total: summaryMatch ? parseInt(summaryMatch[1]) + (parseInt(summaryMatch[2]) || 0) + (parseInt(summaryMatch[3]) || 0) : 0,
    passed: summaryMatch ? parseInt(summaryMatch[1]) : 0,
    failed: summaryMatch && summaryMatch[2] ? parseInt(summaryMatch[2]) : 0,
    skipped: summaryMatch && summaryMatch[3] ? parseInt(summaryMatch[3]) : 0,
    success: failures.length === 0,
    failures,
    coveragePercent,
  };
}

function parseCargoTestOutput(output: string): Partial<TestResult> {
  const resultMatch = output.match(/test result: (\w+)\.\s+(\d+) passed;\s+(\d+) failed;\s+(\d+) ignored/);
  const failures: TestResult['failures'] = [];
  const failPattern = /---- (\S+) stdout ----\n([\s\S]*?)(?=---- |\nfailures:)/g;
  let m;
  while ((m = failPattern.exec(output)) !== null) {
    failures.push({ name: m[1], file: '', message: m[2].trim().substring(0, 500) });
  }

  return {
    total: resultMatch ? parseInt(resultMatch[2]) + parseInt(resultMatch[3]) + parseInt(resultMatch[4]) : 0,
    passed: resultMatch ? parseInt(resultMatch[2]) : 0,
    failed: resultMatch ? parseInt(resultMatch[3]) : 0,
    skipped: resultMatch ? parseInt(resultMatch[4]) : 0,
    success: resultMatch ? resultMatch[1] === 'ok' : false,
    failures,
  };
}

function parsePesterOutput(output: string): Partial<TestResult> {
  try {
    const json = JSON.parse(output);
    return {
      total: json.TotalCount || 0,
      passed: json.PassedCount || 0,
      failed: json.FailedCount || 0,
      skipped: json.SkippedCount || 0,
      success: (json.FailedCount || 0) === 0,
      failures: (json.Failed || []).map((f: { Name: string; ErrorRecord: { Exception: { Message: string } } }) => ({
        name: f.Name, file: '', message: f.ErrorRecord?.Exception?.Message || '',
      })),
    };
  } catch {
    return parseBunTestOutput(output);
  }
}

export const test_runner: ToolDefinition = tool({
  description:
    'Auto-detect and run the project\'s test framework. Returns normalized JSON with pass/fail counts, ' +
    'coverage percentage, and structured failure messages. Supports bun, vitest, jest, mocha, pytest, ' +
    'cargo test, and Pester. Three scope modes: "all" (full suite), "convention" (naming-based file match), ' +
    '"graph" (import graph trace via imports tool).',
  args: {
    scope: tool.schema
      .enum(['all', 'convention', 'graph'])
      .default('all')
      .describe('"all" runs full suite. "convention" runs tests matching source files by naming convention. "graph" uses import graph.'),
    files: tool.schema
      .string()
      .optional()
      .describe('Comma-separated source file paths (required for "convention" and "graph" scopes)'),
    coverage: tool.schema
      .boolean()
      .default(false)
      .describe('Run with coverage reporting enabled'),
    timeout_seconds: tool.schema
      .number()
      .default(120)
      .describe('Maximum execution time in seconds'),
  },
  execute: async (args) => {
    const cwd = process.cwd();
    const framework = detectFramework(cwd);

    if (!framework) {
      return JSON.stringify({
        framework: 'none',
        error: 'No test framework detected. Checked: bun, vitest, jest, mocha, pytest, cargo, pester.',
        success: false,
      }, null, 2);
    }

    let cmd = args.coverage ? framework.coverageCmd : framework.runCmd;
    const startTime = Date.now();

    // Scope filtering: determine which test files to run
    if (args.scope !== 'all' && args.files) {
      const sourceFiles = args.files.split(',').map(f => f.trim());
      let testFiles: string[];

      if (args.scope === 'graph') {
        testFiles = findTestsByGraph(sourceFiles, framework, cwd);
      } else {
        testFiles = findTestsByConvention(sourceFiles, framework, cwd);
      }

      if (testFiles.length === 0) {
        return JSON.stringify({
          framework: framework.name,
          scope: args.scope,
          message: `No test files found for: ${sourceFiles.join(', ')}`,
          total: 0, passed: 0, failed: 0, skipped: 0,
          success: true,
          failures: [],
        }, null, 2);
      }

      // Append test file paths to command
      const fileArgs = testFiles.join(' ');
      switch (framework.name) {
        case 'bun':
          cmd = `bun test ${fileArgs}`;
          break;
        case 'vitest':
          cmd = `npx vitest run ${fileArgs} --reporter=json`;
          break;
        case 'jest':
          cmd = `npx jest ${fileArgs} --json`;
          break;
        case 'pytest':
          cmd = `python -m pytest ${fileArgs} --tb=short -q`;
          break;
        case 'pester':
          cmd = `pwsh -Command "Invoke-Pester -Path ${testFiles.map(f => `'${f}'`).join(',')} -PassThru | ConvertTo-Json -Depth 5"`;
          break;
        default:
          cmd += ` ${fileArgs}`;
      }
    }

    try {
      let output: string;
      try {
        output = execSync(cmd, {
          cwd,
          encoding: 'utf-8',
          timeout: (args.timeout_seconds || 120) * 1000,
          maxBuffer: 10 * 1024 * 1024,
          stdio: ['pipe', 'pipe', 'pipe'],
          env: { ...process.env, FORCE_COLOR: '0', NO_COLOR: '1', CI: 'true' },
        });
      } catch (e: unknown) {
        const execError = e as { stdout?: string; stderr?: string; status?: number };
        output = (execError.stdout || '') + (execError.stderr || '');
      }

      const parsed = framework.parseOutput(output);
      const durationMs = Date.now() - startTime;

      const result: TestResult = {
        framework: framework.name,
        scope: args.scope || 'all',
        command: cmd,
        total: parsed.total || 0,
        passed: parsed.passed || 0,
        failed: parsed.failed || 0,
        skipped: parsed.skipped || 0,
        coveragePercent: parsed.coveragePercent ?? null,
        duration_ms: durationMs,
        success: parsed.success ?? (parsed.failed === 0),
        failures: parsed.failures || [],
      };

      // Include truncated raw output if parsing yielded zero results
      // (likely a parse failure — raw output helps debugging)
      if (result.total === 0 && output.length > 0) {
        result.rawOutput = output.substring(0, 2000);
      }

      return JSON.stringify(result, null, 2);
    } catch (e) {
      return JSON.stringify({
        framework: framework.name,
        scope: args.scope,
        command: cmd,
        error: (e as Error).message,
        success: false,
      }, null, 2);
    }
  },
});
```

### Test Engineer Integration

The test_engineer prompt is updated to use the `test_runner` tool instead of manually constructing CLI invocations.

#### `src/agents/test-engineer.ts` — Append to prompt

```
TOOLS:
You have access to the `test_runner` tool. Use it instead of manually invoking test frameworks.

WORKFLOW (updated):
1. Write test file to the specified OUTPUT path
2. Run tests using the `test_runner` tool:
   - For verification tests: test_runner(scope: "convention", files: "[source file]")
   - For full suite validation: test_runner(scope: "all")
   - For coverage: test_runner(scope: "all", coverage: true)
3. Parse the structured JSON result — do NOT parse terminal output manually
4. Report results using the output format below

If test_runner returns { framework: "none" }, fall back to manual test execution.
```

---

## 2. `symbols` — Export/Type Inventory

### Purpose

AST extraction tool that returns all exported symbols from a file: function names with parameter types and return types, interface/type definitions, class public members, constants. Feeds architect planning, designer scaffolding, and explorer analysis.

### Implementation

#### `src/tools/symbols.ts` (new file)

```typescript
import { execSync } from 'node:child_process';
import * as fs from 'node:fs';
import * as path from 'node:path';
import { type ToolDefinition, tool } from '@opencode-ai/plugin/tool';

interface SymbolInfo {
  name: string;
  kind: 'function' | 'class' | 'interface' | 'type' | 'enum' | 'const' | 'variable' | 'method' | 'property';
  exported: boolean;
  signature: string;
  line: number;
  jsdoc?: string;
}

/**
 * Extract symbols from a TypeScript/JavaScript file using regex-based parsing.
 * Handles: export function, export const, export class, export interface,
 * export type, export enum, export default, and class members.
 */
function extractTSSymbols(filePath: string, cwd: string): SymbolInfo[] {
  const fullPath = path.join(cwd, filePath);
  if (!fs.existsSync(fullPath)) return [];

  const content = fs.readFileSync(fullPath, 'utf-8');
  const lines = content.split('\n');
  const symbols: SymbolInfo[] = [];

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    const lineNum = i + 1;

    // Collect JSDoc comment above this line
    let jsdoc: string | undefined;
    if (i > 0 && lines[i - 1].trim().endsWith('*/')) {
      const jsdocLines: string[] = [];
      for (let j = i - 1; j >= 0; j--) {
        jsdocLines.unshift(lines[j]);
        if (lines[j].trim().startsWith('/**')) break;
      }
      jsdoc = jsdocLines.join('\n').trim();
      if (jsdoc.length > 300) jsdoc = jsdoc.substring(0, 300) + '...';
    }

    // Exported function
    const fnMatch = line.match(/^export\s+(?:async\s+)?function\s+(\w+)\s*(<[^>]*>)?\s*\(([^)]*)\)(?:\s*:\s*(.+?))?(?:\s*\{|$)/);
    if (fnMatch) {
      symbols.push({
        name: fnMatch[1],
        kind: 'function',
        exported: true,
        signature: `function ${fnMatch[1]}${fnMatch[2] || ''}(${fnMatch[3].trim()})${fnMatch[4] ? `: ${fnMatch[4].trim()}` : ''}`,
        line: lineNum,
        jsdoc,
      });
      continue;
    }

    // Exported const (with type annotation or arrow function)
    const constMatch = line.match(/^export\s+const\s+(\w+)(?:\s*:\s*(.+?))?\s*=/);
    if (constMatch) {
      // Check if it's an arrow function
      const restOfLine = line.substring(line.indexOf('=') + 1).trim();
      const isArrow = restOfLine.startsWith('(') || restOfLine.startsWith('async (') ||
                       restOfLine.match(/^\w+\s*=>/);
      symbols.push({
        name: constMatch[1],
        kind: isArrow ? 'function' : 'const',
        exported: true,
        signature: `const ${constMatch[1]}${constMatch[2] ? `: ${constMatch[2].trim()}` : ''}`,
        line: lineNum,
        jsdoc,
      });
      continue;
    }

    // Exported class
    const classMatch = line.match(/^export\s+(?:abstract\s+)?class\s+(\w+)(?:\s+(?:extends|implements)\s+(.+?))?(?:\s*\{|$)/);
    if (classMatch) {
      symbols.push({
        name: classMatch[1],
        kind: 'class',
        exported: true,
        signature: `class ${classMatch[1]}${classMatch[2] ? ` extends/implements ${classMatch[2].trim()}` : ''}`,
        line: lineNum,
        jsdoc,
      });

      // Scan class body for public members
      let braceDepth = (line.match(/\{/g) || []).length - (line.match(/\}/g) || []).length;
      for (let j = i + 1; j < lines.length && braceDepth > 0; j++) {
        const memberLine = lines[j];
        braceDepth += (memberLine.match(/\{/g) || []).length - (memberLine.match(/\}/g) || []).length;

        // Public method
        const methodMatch = memberLine.match(/^\s+(?:public\s+)?(?:async\s+)?(\w+)\s*\(([^)]*)\)(?:\s*:\s*(.+?))?(?:\s*\{|;|$)/);
        if (methodMatch && !memberLine.includes('private') && !memberLine.includes('protected') && !memberLine.trim().startsWith('//')) {
          symbols.push({
            name: `${classMatch[1]}.${methodMatch[1]}`,
            kind: 'method',
            exported: true,
            signature: `${methodMatch[1]}(${methodMatch[2].trim()})${methodMatch[3] ? `: ${methodMatch[3].trim()}` : ''}`,
            line: j + 1,
          });
        }

        // Public property
        const propMatch = memberLine.match(/^\s+(?:public\s+)?(?:readonly\s+)?(\w+)(?:\?)?:\s*(.+?)(?:\s*[;=]|$)/);
        if (propMatch && !memberLine.includes('private') && !memberLine.includes('protected') && !memberLine.trim().startsWith('//')) {
          symbols.push({
            name: `${classMatch[1]}.${propMatch[1]}`,
            kind: 'property',
            exported: true,
            signature: `${propMatch[1]}: ${propMatch[2].trim()}`,
            line: j + 1,
          });
        }
      }
      continue;
    }

    // Exported interface
    const ifaceMatch = line.match(/^export\s+interface\s+(\w+)(?:\s*<([^>]+)>)?(?:\s+extends\s+(.+?))?(?:\s*\{|$)/);
    if (ifaceMatch) {
      symbols.push({
        name: ifaceMatch[1],
        kind: 'interface',
        exported: true,
        signature: `interface ${ifaceMatch[1]}${ifaceMatch[2] ? `<${ifaceMatch[2]}>` : ''}${ifaceMatch[3] ? ` extends ${ifaceMatch[3].trim()}` : ''}`,
        line: lineNum,
        jsdoc,
      });
      continue;
    }

    // Exported type
    const typeMatch = line.match(/^export\s+type\s+(\w+)(?:\s*<([^>]+)>)?\s*=/);
    if (typeMatch) {
      const typeValue = line.substring(line.indexOf('=') + 1).trim().substring(0, 100);
      symbols.push({
        name: typeMatch[1],
        kind: 'type',
        exported: true,
        signature: `type ${typeMatch[1]}${typeMatch[2] ? `<${typeMatch[2]}>` : ''} = ${typeValue}`,
        line: lineNum,
        jsdoc,
      });
      continue;
    }

    // Exported enum
    const enumMatch = line.match(/^export\s+(?:const\s+)?enum\s+(\w+)/);
    if (enumMatch) {
      symbols.push({
        name: enumMatch[1],
        kind: 'enum',
        exported: true,
        signature: `enum ${enumMatch[1]}`,
        line: lineNum,
        jsdoc,
      });
      continue;
    }

    // Export default
    const defaultMatch = line.match(/^export\s+default\s+(?:function\s+)?(\w+)/);
    if (defaultMatch) {
      symbols.push({
        name: defaultMatch[1],
        kind: 'function',
        exported: true,
        signature: `default ${defaultMatch[1]}`,
        line: lineNum,
        jsdoc,
      });
    }
  }

  return symbols;
}

/**
 * Extract symbols from a Python file.
 */
function extractPythonSymbols(filePath: string, cwd: string): SymbolInfo[] {
  const fullPath = path.join(cwd, filePath);
  if (!fs.existsSync(fullPath)) return [];

  const content = fs.readFileSync(fullPath, 'utf-8');
  const lines = content.split('\n');
  const symbols: SymbolInfo[] = [];

  // Check __all__ for explicit exports
  const allMatch = content.match(/__all__\s*=\s*\[([^\]]+)\]/);
  const explicitExports = allMatch
    ? allMatch[1].split(',').map(s => s.trim().replace(/['"]/g, ''))
    : null;

  for (let i = 0; i < lines.length; i++) {
    const line = lines[i];
    if (line.startsWith(' ') || line.startsWith('\t')) continue; // Skip nested definitions

    // Functions
    const fnMatch = line.match(/^(?:async\s+)?def\s+(\w+)\s*\(([^)]*)\)(?:\s*->\s*(.+?))?:/);
    if (fnMatch && !fnMatch[1].startsWith('_')) {
      const exported = !explicitExports || explicitExports.includes(fnMatch[1]);
      symbols.push({
        name: fnMatch[1],
        kind: 'function',
        exported,
        signature: `def ${fnMatch[1]}(${fnMatch[2].trim()})${fnMatch[3] ? ` -> ${fnMatch[3].trim()}` : ''}`,
        line: i + 1,
      });
    }

    // Classes
    const classMatch = line.match(/^class\s+(\w+)(?:\(([^)]*)\))?:/);
    if (classMatch && !classMatch[1].startsWith('_')) {
      const exported = !explicitExports || explicitExports.includes(classMatch[1]);
      symbols.push({
        name: classMatch[1],
        kind: 'class',
        exported,
        signature: `class ${classMatch[1]}${classMatch[2] ? `(${classMatch[2].trim()})` : ''}`,
        line: i + 1,
      });
    }

    // Module-level constants (UPPER_CASE)
    const constMatch = line.match(/^([A-Z][A-Z0-9_]+)\s*[:=]/);
    if (constMatch) {
      symbols.push({
        name: constMatch[1],
        kind: 'const',
        exported: true,
        signature: line.trim().substring(0, 100),
        line: i + 1,
      });
    }
  }

  return symbols;
}

export const symbols: ToolDefinition = tool({
  description:
    'Extract all exported symbols from a source file: functions with signatures, ' +
    'classes with public members, interfaces, types, enums, constants. ' +
    'Supports TypeScript/JavaScript and Python. Use for architect planning, ' +
    'designer scaffolding, and understanding module public API surface.',
  args: {
    file: tool.schema
      .string()
      .describe('File path to extract symbols from (e.g., "src/auth/login.ts")'),
    exported_only: tool.schema
      .boolean()
      .default(true)
      .describe('If true, only return exported/public symbols. If false, include all top-level symbols.'),
  },
  execute: async (args) => {
    const cwd = process.cwd();
    const ext = path.extname(args.file);
    let syms: SymbolInfo[];

    switch (ext) {
      case '.ts':
      case '.tsx':
      case '.js':
      case '.jsx':
      case '.mjs':
      case '.cjs':
        syms = extractTSSymbols(args.file, cwd);
        break;
      case '.py':
        syms = extractPythonSymbols(args.file, cwd);
        break;
      default:
        return JSON.stringify({
          file: args.file,
          error: `Unsupported file extension: ${ext}. Supported: .ts, .tsx, .js, .jsx, .py`,
          symbols: [],
        }, null, 2);
    }

    if (args.exported_only) {
      syms = syms.filter(s => s.exported);
    }

    return JSON.stringify({
      file: args.file,
      symbolCount: syms.length,
      symbols: syms,
    }, null, 2);
  },
});
```

### Architect Integration

Add `symbols` to the `Available Tools` section in `src/agents/architect.ts`:

```
  symbols — Extract exported symbols from a file: functions, classes, interfaces, types. Use during Phase 2 (discovery) and Phase 4 (planning) to understand module APIs without reading entire files.
```

---

## 3. `checkpoint` — Safe Rollback Points

### Purpose

Creates and restores git-based save points for multi-file changes. Uses real commits (not stash) for reliable rollback. The architect creates a checkpoint before coder starts a risky multi-file refactor and restores if integration analysis or tests reveal critical issues.

### Implementation

#### `src/tools/checkpoint.ts` (new file)

```typescript
import { execSync } from 'node:child_process';
import * as fs from 'node:fs';
import * as path from 'node:path';
import { type ToolDefinition, tool } from '@opencode-ai/plugin/tool';

const CHECKPOINT_PREFIX = 'swarm-checkpoint';
const CHECKPOINT_LOG = '.swarm/checkpoints.json';

interface CheckpointEntry {
  label: string;
  sha: string;
  timestamp: string;
  filesChanged: number;
}

/**
 * Read the checkpoint log, creating it if it doesn't exist.
 */
function readCheckpointLog(cwd: string): CheckpointEntry[] {
  const logPath = path.join(cwd, CHECKPOINT_LOG);
  try {
    if (fs.existsSync(logPath)) {
      return JSON.parse(fs.readFileSync(logPath, 'utf-8'));
    }
  } catch { /* ignore corrupt log */ }
  return [];
}

/**
 * Write the checkpoint log.
 */
function writeCheckpointLog(cwd: string, entries: CheckpointEntry[]): void {
  const logPath = path.join(cwd, CHECKPOINT_LOG);
  const dir = path.dirname(logPath);
  if (!fs.existsSync(dir)) fs.mkdirSync(dir, { recursive: true });
  fs.writeFileSync(logPath, JSON.stringify(entries, null, 2));
}

export const checkpoint: ToolDefinition = tool({
  description:
    'Create and restore git-based save points for multi-file changes. ' +
    '"save" commits current working tree as a checkpoint. "restore" resets to a saved checkpoint (soft reset, preserves working tree for inspection). ' +
    '"list" shows all checkpoints. "delete" removes a checkpoint. ' +
    'NOTE: Creates real git commits. Users should squash checkpoint commits before merging.',
  args: {
    action: tool.schema
      .enum(['save', 'restore', 'list', 'delete'])
      .describe('"save" creates checkpoint, "restore" resets to it, "list" shows all, "delete" removes one'),
    label: tool.schema
      .string()
      .optional()
      .describe('Checkpoint label (required for save, restore, delete)'),
  },
  execute: async (args) => {
    const cwd = process.cwd();

    // Verify git repo
    try {
      execSync('git rev-parse --is-inside-work-tree', { cwd, encoding: 'utf-8', timeout: 5000 });
    } catch {
      return JSON.stringify({ error: 'Not a git repository' });
    }

    switch (args.action) {
      case 'save': {
        if (!args.label) return JSON.stringify({ error: 'Label required for save' });

        const sanitizedLabel = args.label.replace(/[^a-zA-Z0-9_-]/g, '_');

        // Stage everything and commit
        try {
          execSync('git add -A', { cwd, timeout: 10000 });

          // Check if there are changes to commit
          const status = execSync('git status --porcelain', { cwd, encoding: 'utf-8', timeout: 5000 }).trim();
          if (!status) {
            return JSON.stringify({
              action: 'save',
              label: sanitizedLabel,
              message: 'No changes to checkpoint — working tree is clean.',
            });
          }

          const filesChanged = status.split('\n').filter(Boolean).length;

          execSync(
            `git commit -m "${CHECKPOINT_PREFIX}: ${sanitizedLabel}" --no-verify`,
            { cwd, encoding: 'utf-8', timeout: 15000 }
          );

          const sha = execSync('git rev-parse HEAD', { cwd, encoding: 'utf-8', timeout: 5000 }).trim();

          // Log the checkpoint
          const log = readCheckpointLog(cwd);
          log.push({
            label: sanitizedLabel,
            sha,
            timestamp: new Date().toISOString(),
            filesChanged,
          });
          writeCheckpointLog(cwd, log);

          return JSON.stringify({
            action: 'save',
            label: sanitizedLabel,
            sha,
            filesChanged,
            message: `Checkpoint saved. ${filesChanged} files committed. To undo later: checkpoint(action: "restore", label: "${sanitizedLabel}")`,
          }, null, 2);
        } catch (e) {
          return JSON.stringify({ action: 'save', error: (e as Error).message });
        }
      }

      case 'restore': {
        if (!args.label) return JSON.stringify({ error: 'Label required for restore' });

        const log = readCheckpointLog(cwd);
        const entry = log.find(e => e.label === args.label);

        if (!entry) {
          return JSON.stringify({
            action: 'restore',
            error: `Checkpoint "${args.label}" not found. Available: ${log.map(e => e.label).join(', ') || 'none'}`,
          });
        }

        try {
          // Soft reset preserves working tree so architect can inspect what would be lost
          execSync(`git reset --soft ${entry.sha}`, { cwd, timeout: 10000 });

          return JSON.stringify({
            action: 'restore',
            label: args.label,
            sha: entry.sha,
            message: `Restored to checkpoint "${args.label}" (${entry.sha.substring(0, 8)}). Working tree preserved — unstaged changes show what was rolled back.`,
          }, null, 2);
        } catch (e) {
          return JSON.stringify({ action: 'restore', error: (e as Error).message });
        }
      }

      case 'list': {
        const log = readCheckpointLog(cwd);
        return JSON.stringify({
          action: 'list',
          checkpoints: log,
          count: log.length,
        }, null, 2);
      }

      case 'delete': {
        if (!args.label) return JSON.stringify({ error: 'Label required for delete' });

        const log = readCheckpointLog(cwd);
        const filtered = log.filter(e => e.label !== args.label);

        if (filtered.length === log.length) {
          return JSON.stringify({ action: 'delete', error: `Checkpoint "${args.label}" not found` });
        }

        writeCheckpointLog(cwd, filtered);
        return JSON.stringify({
          action: 'delete',
          label: args.label,
          message: `Checkpoint "${args.label}" removed from log. Git commit still exists in history.`,
        }, null, 2);
      }

      default:
        return JSON.stringify({ error: `Unknown action: ${args.action}` });
    }
  },
});
```

### Architect Integration

Add `checkpoint` to `Available Tools` in `src/agents/architect.ts`:

```
  checkpoint — Create/restore git save points. save(label) before risky changes, restore(label) on failure. Uses real commits (squash before merge).
```

Add **Rule 11** to `## RULES`:

```
11. **CHECKPOINTS**: Before delegating multi-file refactoring tasks to {{AGENT_PREFIX}}coder (3+ files affected), create a checkpoint: `checkpoint(action: "save", label: "pre-[task-id]")`. If integration analysis or tests reveal critical failures that would be faster to redo than fix, restore the checkpoint instead of iterating: `checkpoint(action: "restore", label: "pre-[task-id]")`.
```

---

## 4. Tool Registration

#### `src/tools/index.ts`

```typescript
export { detect_domains } from './domain-detector';
export { extract_code_blocks } from './file-extractor';
export { gitingest, fetchGitingest, type GitingestArgs } from './gitingest';
export { diff } from './diff';
export { imports } from './imports';
export { lint } from './lint';
export { secretscan } from './secretscan';
// v6.4
export { test_runner } from './test-runner';
export { symbols } from './symbols';
export { checkpoint } from './checkpoint';
```

#### `src/index.ts`

```typescript
import { detect_domains, extract_code_blocks, gitingest, diff, imports, lint, secretscan, test_runner, symbols, checkpoint } from './tools';

tool: {
  detect_domains, extract_code_blocks, gitingest,
  diff, imports, lint, secretscan,
  test_runner, symbols, checkpoint,
},
```

---

## 5. Configuration

#### `src/config/schema.ts`

```typescript
checkpoint: z.object({
  enabled: z.boolean().default(true),
  auto_checkpoint_threshold: z.number().min(1).max(20).default(3),
}).optional(),
```

`auto_checkpoint_threshold` defines the minimum number of files in a task before the architect auto-creates a checkpoint (default: 3). Injected via system-enhancer.

---

## 6. Test Requirements

### `test_runner`

- Unit: Detect bun from bun.lockb.
- Unit: Detect vitest from devDependencies.
- Unit: Detect jest from devDependencies.
- Unit: Detect pytest from pyproject.toml.
- Unit: Detect cargo from Cargo.toml.
- Unit: Detect Pester from .Tests.ps1 files.
- Unit: `findTestsByConvention` maps `src/auth/login.ts` → `src/auth/login.test.ts`.
- Unit: `findTestsByConvention` maps `src/auth/login.ts` → `tests/auth/login.test.ts`.
- Unit: `findTestsByConvention` maps `src/module.py` → `tests/test_module.py`.
- Unit: Each parser extracts pass/fail/skip counts correctly from sample output.
- Unit: Jest JSON parser handles preamble before JSON object.
- Integration: Full `bun test` execution on the swarm project itself.

### `symbols`

- Unit: Extract exported function from `export function foo(x: string): void`.
- Unit: Extract exported const from `export const BAR = 42`.
- Unit: Extract exported arrow function from `export const fn = (x: string) => {}`.
- Unit: Extract exported class with public methods.
- Unit: Extract exported interface with generics.
- Unit: Extract exported type alias.
- Unit: Extract exported enum.
- Unit: Extract export default.
- Unit: `exported_only: false` includes non-exported top-level symbols.
- Unit: Python function extraction from `def foo(x: int) -> str:`.
- Unit: Python class extraction.
- Unit: Python `__all__` filtering.

### `checkpoint`

- Unit: `save` creates commit with correct message prefix.
- Unit: `save` on clean working tree returns "no changes" message.
- Unit: `restore` performs soft reset to saved SHA.
- Unit: `restore` with unknown label returns error with available labels.
- Unit: `list` returns all logged checkpoints.
- Unit: `delete` removes entry from log.
- Unit: Checkpoint log persists across calls.
- Integration: save → modify file → restore → verify file reverted.

---

## 7. Implementation Order

1. `src/tools/symbols.ts` — No dependencies.
2. `src/tools/test-runner.ts` — Uses `imports` from v6.3 for graph mode (convention mode works independently).
3. `src/tools/checkpoint.ts` — No dependencies.
4. `src/tools/index.ts` — Add all three exports.
5. `src/index.ts` — Register all three tools.
6. `src/config/schema.ts` — Add `checkpoint` config block.
7. `src/agents/architect.ts` — Add tools to Available Tools, add Rule 11.
8. `src/agents/test-engineer.ts` — Update prompt to use `test_runner` tool.
9. Tests for all of the above.
